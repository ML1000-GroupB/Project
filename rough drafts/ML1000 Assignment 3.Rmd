---
title: "ML1000 Assignment 3"
author: "Crystal Zhu"
date: "07/03/2021"
output:
  pdf_document: default
  html_document: default
---

## Data Understanding


### How do we merge the data files?


There are six data files, excluding the sample_submission.csv file, from the Instacart Market Basket Analysis data - aisles.csv, departments.csv, order_products__train.csv, order_products__prior.csv, orders.csv and products.csv.

(Add data file descriptions later!)

Steps:

1. Merged the aisles data with the products data to obtain Merged dataset 1, so that we know which aisle each product belongs to.

2. Combined the Merged dataset 1 with the department data to obtain Merged dataset 2, so we know which aisle and department each product is from.

3. Add Merged dataset 2, which contains product full information, to order_products__train and order_products__prior files, respectively, to obtain Merged dataset 3 (Train) and Merged dataset 4 (Prior), so that we know the product information (e.g. product names, aisles and departments they belong to) of the products in the training and prior orders.






```{r, message=FALSE, warning=FALSE}

library(arules)


####### Convert the merged dataset into a TRANSACTION FORM FOR R ############
X=read.csv("C:/Users/yunan/Downloads/York U/Machine Learning Cert/Assignment 3/data/orders_TRAIN_products_MERGED.csv")


#split(x,f) divides the data in the vector x into the groups defined by f
#split(x,f) returns a list, and the components of the list are named by the levels of f
#so basically it returns the frequency table at each level of f(aka, the frequency of each product in our cases)


X$order_id=as.factor(X$order_id)
X$product_id=as.factor(X$product_id)

X=X[order(X$order_id),]

#summarise() is typically used on grouped data created by group_by(). The output will have one row for each group (category)
#arrange(): Arrange/order Rows By Variables

#identify the top 50 frequently bought products
library(dplyr)
top_products <- X %>% 
  group_by(product_id) %>% 
  summarise(totalfreq=n()) %>%
  top_n(50) %>%
  arrange(desc(totalfreq))

top_productnames <- X %>% 
  group_by(product_name) %>% 
  summarise(totalfreq=n()) %>%
  top_n(50) %>%
  arrange(desc(totalfreq))

#when change top 50 products to top 100 products, the rule may not change much because the frequent pairs may come mostly from the frequent products, rather than the less frequently bought items


X_keep=filter(X, product_id %in% top_products$product_id)

X_sub=subset(X_keep,select=c(order_id,product_id,product_name))
length(unique(X_sub$product_name))
write.csv(X_sub,"C:/Users/yunan/Downloads/York U/Machine Learning Cert/Assignment 3/data/orders_TRAIN_products_MERGED_subset for association rule.csv",row.names = F )
#X_keep1=X_keep[order(X_keep$product_id),]

set.seed(123)

#length(unique(X$product_name))
#39,123 unique product names

length(unique(X_keep$product_name))
#101 products - because there's a tie

#create the item list
Order_by_product <- split(X_keep$product_name, X_keep$order_id)

Order_by_product[[1]]
#the first element of Order_by_product is all the items from the first order
length(Order_by_product)
#97
length(unique(X_keep$order_id))
#97 - so the length of Order_by_product is the number of orders

#Coerce the Item List to the Transactions class
#convert transaction data in dataframe to transaction object
X1_trans <- as(Order_by_product, "transactions")

X1_trans@data@i[1:5]
#the product index/position from each order sequentially
X1_trans@data@p[1:5]
#the cummulative number of iterms from each order
X1_trans@data@Dim
#number of unique products * number of orders
X1_trans@itemInfo$labels[1:5]
#labels contain the product names in our case

library(RColorBrewer)
itemFrequencyPlot(X1_trans,topN=10,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Item Frequency Plot")


#apply apriori rule
X_apri_rule=apriori(X1_trans,parameter=list(supp=0.0015, conf=0.4))
                                                       
saveRDS(X_apri_rule,"C:/Users/yunan/Downloads/York U/Machine Learning Cert/Assignment 3/data/trained_rules.rds")

inspect(X_apri_rule[1:10])

#return the rules that contain "Organic Strawberries" on the left side (in the basket)
strawrule=subset(X_apri_rule, lhs %in% "Organic Hass Avocado")

inspect(strawrule)

rhs(strawrule)

X_keep$product_name[strawrule@rhs@data@i+1]

unique(strawrule@rhs@itemInfo$labels[strawrule@rhs@data@i+1])


#if we select orders from the same person/if the number of transactions is not large, the overlapping of products from different products tend to be small - so the rules are mostly of single products!

 topRules <- head(X_apri_rule, n = 15, by = "lift")
inspect(topRules)

 summary(X_apri_rule)
 
 
 topRules <- head(X_apri_rule, n = 10, by = "lift")

 library(arulesViz)
 #interactive plot in html
 #plot(topRules, method = "graph",  engine = "htmlwidget",main="Top 10 rules")
  plot(topRules, method = "graph",  main="Top 10 rules")

```


